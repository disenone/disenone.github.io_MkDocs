---
layout: post
title: Documento de instrucciones del complemento UE AIChatPlus
tags:
- dev
- game
- UE
- UnreanEngine
- UE4
- UE5
- Editor
- Editor Plus
- Editor Plugin
- AI Chat
- Chatbot
- Image Generation
- OpenAI
- Azure
- Claude
- Gemini
- Ollama
description: Documentaci√≥n de UE Plug-in AIChatPlus
---

<meta property="og:title" content="UE Êèí‰ª∂ AIChatPlus ËØ¥ÊòéÊñáÊ°£" />

#UE Êèí‰ª∂ AIChatPlus Gu√≠a de Documentaci√≥n

##Dep√≥sito p√∫blico

[UE.AIChatPlus.Public](https://github.com/disenone/UE.AIChatPlus.Public)

##Obtener complemento

[AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

##Introducci√≥n del complemento

Este complemento es compatible con UE5.2+.

UE.AIChatPlus es un complemento de UnrealEngine que permite la comunicaci√≥n con varios servicios de chat de IA GPT. Actualmente es compatible con OpenAI (ChatGPT, DALL-E), Azure OpenAI (ChatGPT, DALL-E), Claude, Google Gemini, Ollama y llama.cpp en modo offline local. En el futuro, seguir√° agregando soporte para m√°s proveedores de servicios. Su implementaci√≥n se basa en solicitudes REST as√≠ncronas, lo que asegura un alto rendimiento y facilita a los desarrolladores de UE integrar estos servicios de chat de IA.

UE.AIChatPlus tambi√©n incluye una herramienta de edici√≥n que permite utilizar directamente los servicios de chat de IA en el editor, generar texto e im√°genes, y analizar im√°genes, entre otras funciones.

##Instrucciones de uso

###Herramienta de chat del editor.

La barra de men√∫ Tools -> AIChatPlus -> AIChat abre las herramientas de chat del editor proporcionadas por el complemento.

![](assets/img/2024-ue-aichatplus/chat_tool3.png)


La herramienta es compatible con la generaci√≥n de texto, chat de texto, generaci√≥n de im√°genes y an√°lisis de im√°genes.

La interfaz de la herramienta es aproximadamente la siguiente:

![text chat](assets/img/2024-ue-aichatplus/chat_tool2.png)

![image chat](assets/img/2024-ue-aichatplus/chat_tool.png)

####Funci√≥n principal

* Modelo grande sin conexi√≥n: Integraci√≥n de la biblioteca llama.cpp para admitir la ejecuci√≥n sin conexi√≥n de modelos grandes a nivel local.

* Chat de texto: haz clic en el bot√≥n `Nuevo chat` en la esquina inferior izquierda para crear una nueva sesi√≥n de chat de texto.

* Generaci√≥n de im√°genes: haz clic en el bot√≥n `Nueva imagen pto de charla` en la esquina inferior izquierda para iniciar una nueva sesi√≥n de generaci√≥n de im√°genes.

An√°lisis de im√°genes: Algunos servicios de chat en la funci√≥n `New Chat` admiten el env√≠o de im√°genes, como Claude, Google Gemini. Simplemente haz clic en los botones de üñºÔ∏è o üé® en la parte superior del cuadro de entrada para cargar la imagen que deseas enviar.

Translate these texts into Spanish language:

* Soporte de Blueprint: Soporte para la creaci√≥n de solicitudes API a trav√©s de Blueprint, para funciones como chat de texto, generaci√≥n de im√°genes, entre otras.

Establecer el rol actual de la conversaci√≥n: El men√∫ desplegable en la parte superior del cuadro de chat puede definir el rol actual para enviar texto, lo que permite simular diferentes roles para ajustar la conversaci√≥n con la inteligencia artificial.

Eliminar conversaci√≥n: Al hacer clic en la ‚ùå en la parte superior del cuadro de chat se pueden borrar los mensajes anteriores de la conversaci√≥n actual.

* Plantilla de di√°logo: incorpora cientos de plantillas de configuraci√≥n de di√°logo para manejar f√°cilmente problemas comunes.

Traduce este texto al idioma espa√±ol:

* Configuraci√≥n global: al hacer clic en el bot√≥n `Setting` en la esquina inferior izquierda, se puede abrir la ventana de configuraci√≥n global. Se pueden establecer el chat de texto predeterminado, los servicios de API para generar im√°genes y los par√°metros espec√≠ficos de cada servicio de API. La configuraci√≥n se guardar√° autom√°ticamente en la ruta del proyecto `$(ProjectFolder)/Saved/AIChatPlusEditor`.

Translate these text into Spanish language:

* Configuraci√≥n de la conversaci√≥n: Al presionar el bot√≥n de ajustes en la parte superior de la ventana de chat, se puede abrir la ventana de configuraci√≥n de la conversaci√≥n actual. Permite modificar el nombre de la conversaci√≥n, cambiar el servicio de API utilizado en la conversaci√≥n, y ajustar par√°metros espec√≠ficos de API para cada conversaci√≥n de manera independiente. La configuraci√≥n de la conversaci√≥n se guarda autom√°ticamente en `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions`

Modificar contenido del chat: al desplazar el rat√≥n sobre el contenido del chat, aparecer√° un bot√≥n de configuraci√≥n junto al contenido individual, que permite regenerar, modificar, copiar o eliminar el contenido, as√≠ como regenerar contenido debajo (para contenido de usuario).

* Visualizaci√≥n de im√°genes: Para la generaci√≥n de im√°genes, al hacer clic en una imagen se abrir√° la ventana de visualizaci√≥n de im√°genes (ImageViewer), que permite guardar la imagen como PNG/Textura UE, las texturas se pueden ver directamente en el Explorador de contenido (Content Browser), lo que facilita su uso dentro del editor. Tambi√©n, se puede eliminar, volver a generar o continuar generando m√°s im√°genes. Para los editores en Windows, tambi√©n se puede copiar im√°genes, lo que permite copiarlas directamente al portapapeles para facilitar su uso. Las im√°genes generadas en la sesi√≥n tambi√©n se guardar√°n autom√°ticamente en la carpeta de cada sesi√≥n, generalmente en la ruta `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions/${GUID}/images`.

Planificaci√≥n:

![blueprint](assets/img/2024-ue-aichatplus/blueprint.png)

Configuraci√≥n global:

![global settings](assets/img/2024-ue-aichatplus/global_setting.png)

Configuraci√≥n de la conversaci√≥n:

![session settings](assets/img/2024-ue-aichatplus/session_setting.png)

Editar el contenido del chat:

![chat edit](assets/img/2024-ue-aichatplus/chat_edit.png)

Visor de im√°genes:

![image viewer](assets/img/2024-ue-aichatplus/image_viewer.png)

Utilizar modelos grandes sin conexi√≥n.

![offline model](assets/img/2024-ue-aichatplus/offline_model.png)

Plantilla de di√°logo

![system template](assets/img/2024-ue-aichatplus/system_template.png)

###Introducci√≥n al c√≥digo central

En la actualidad, el complemento est√° dividido en los siguientes m√≥dulos:

* AIChatPlusCommon: M√≥dulo de tiempo de ejecuci√≥n, encargado de manejar las solicitudes de env√≠o de diversas API de inteligencia artificial y analizar el contenido de las respuestas.

* AIChatPlusEditor: M√≥dulo de editor, responsable de implementar la herramienta de chat de AI en el editor.

* AIChatPlusCllama: M√≥dulo en tiempo de ejecuci√≥n (Runtime), encargado de encapsular las interfaces y par√°metros de llama.cpp, logrando as√≠ la ejecuci√≥n offline de modelos grandes

* Thirdparty/LLAMACpp: M√≥dulo de tercero en tiempo de ejecuci√≥n (Runtime) que integra la biblioteca din√°mica y archivos de cabecera de llama.cpp.

Traduce este texto al espa√±ol:

El UClass encargado espec√≠ficamente de enviar las solicitudes es FAIChatPlus_xxxChatRequest, cada servicio de API tiene su propia UClass de solicitud independiente. Las respuestas a las solicitudes se obtienen a trav√©s de dos UClass diferentes: UAIChatPlus_ChatHandlerBase y UAIChatPlus_ImageHandlerBase, simplemente hay que registrar los delegados de devoluci√≥n de llamada correspondientes.

Antes de enviar la solicitud, es necesario configurar los par√°metros de la API y el mensaje a enviar, esto se realiza mediante FAIChatPlus_xxxChatRequestBody. El contenido espec√≠fico de la respuesta tambi√©n se analiza en FAIChatPlus_xxxChatResponseBody, que se puede obtener a trav√©s de una interfaz espec√≠fica al recibir una devoluci√≥n de llamada.

M√°s detalles del c√≥digo fuente disponibles en la tienda de UE: [AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

##Gu√≠a de uso

###Utiliza el modelo sin conexi√≥n del archivo llama.cpp en la herramienta del editor.

A continuaci√≥n se explica c√≥mo utilizar el modelo offline llama.cpp en la herramienta de edici√≥n AIChatPlus.

* Primero, descarga el modelo offline desde el sitio web de HuggingFace: [Qwen1.5-1.8B-Chat-Q8_0.gguf](https://huggingface.co/second-state/Qwen1.5-1.8B-Chat-GGUF/resolve/main/Qwen1.5-1.8B-Chat-Q8_0.gguf)

Coloca el modelo en una carpeta espec√≠fica, por ejemplo, dentro del directorio del proyecto de juegos Content/LLAMA.

```shell
E:/UE/projects/FP_Test1/Content/LLAMA
> ls
qwen1.5-1_8b-chat-q8_0.gguf*
```

Abre la herramienta de edici√≥n AIChatPlus: Herramientas -> AIChatPlus -> AIChat, crea una nueva sesi√≥n de chat y abre la p√°gina de configuraci√≥n de la sesi√≥n.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_1.png)

Establece la Api en Cllama, activa la Configuraci√≥n de Api Personalizada, agrega la ruta de b√∫squeda de modelos y elige un modelo.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_2.png)

¬°Comienza a conversar!

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_3.png)

###El c√≥digo utiliza el modelo offline llamado llama.cpp

La siguiente explicaci√≥n muestra c√≥mo utilizar el modelo sin conexi√≥n llama.cpp en el c√≥digo.

Primero, tambi√©n es necesario descargar el archivo del modelo en Content/LLAMA.

Modifique el c√≥digo para agregar un comando y enviar un mensaje al modelo sin conexi√≥n dentro de dicho comando.

```c++
#include "Common/AIChatPlus_Log.h"
#include "Common_Cllama/AIChatPlus_CllamaChatRequest.h"

void AddTestCommand()
{
	IConsoleManager::Get().RegisterConsoleCommand(
		TEXT("AIChatPlus.TestChat"),
		TEXT("Test Chat."),
		FConsoleCommandDelegate::CreateLambda([]()
		{
			if (!FModuleManager::GetModulePtr<FAIChatPlusCommon>(TEXT("AIChatPlusCommon"))) return;

			TWeakObjectPtr<UAIChatPlus_ChatHandlerBase> HandlerObject = UAIChatPlus_ChatHandlerBase::New();
			// Cllama
			FAIChatPlus_CllamaChatRequestOptions Options;
			Options.ModelPath.FilePath = FPaths::ProjectContentDir() / "LLAMA" / "qwen1.5-1_8b-chat-q8_0.gguf";
			Options.NumPredict = 400;
			Options.bStream = true;
			// Options.StopSequences.Emplace(TEXT("json"));
			auto RequestPtr = UAIChatPlus_CllamaChatRequest::CreateWithOptionsAndMessages(
				Options,
				{
					{"You are a chat bot", EAIChatPlus_ChatRole::System},
					{"who are you", EAIChatPlus_ChatRole::User}
				});

			HandlerObject->BindChatRequest(RequestPtr);
			const FName ApiName = TEnumTraits<EAIChatPlus_ChatApiProvider>::ToName(RequestPtr->GetApiProvider());

			HandlerObject->OnMessage.AddLambda([ApiName](const FString& Message)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] Message: [%s]"), *ApiName.ToString(), *Message);
			});
			HandlerObject->OnStarted.AddLambda([ApiName]()
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestStarted"), *ApiName.ToString());
			});
			HandlerObject->OnFailed.AddLambda([ApiName](const FAIChatPlus_ResponseErrorBase& InError)
			{
				UE_LOG(AIChatPlus_Internal, Error, TEXT("TestChat[%s] RequestFailed: %s "), *ApiName.ToString(), *InError.GetDescription());
			});
			HandlerObject->OnUpdated.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestUpdated"), *ApiName.ToString());
			});
			HandlerObject->OnFinished.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestFinished"), *ApiName.ToString());
			});

			RequestPtr->SendRequest();
		}),
		ECVF_Default
	);
}
```

* Despu√©s de compilar de nuevo, simplemente utiliza el comando en la consola del editor Cmd y podr√°s ver los resultados de la salida del gran modelo en el registro OutputLog.

![guide code](assets/img/2024-ue-aichatplus/guide_code_1.png)

###La implementaci√≥n del modelo fuera de l√≠nea de blueprint se llama llama.cpp.

Instrucciones sobre c√≥mo utilizar el modelo fuera de l√≠nea llama.cpp en un blueprint.

* En el blueprint, crea un nodo con el bot√≥n derecho llamado `Enviar solicitud de chat de Cllama`

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_1.png)

Cree el nodo Options y establezca `Stream=true, ModelPath="E:\UE\projects\FP_Test1\Content\LLAMA\qwen1.5-1_8b-chat-q8_0.gguf"`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_2.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_3.png)

*Crear Messages, agregar un System Message y un User Message respectivamente*

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_4.png)

*Crear Delegate para recibir informaci√≥n de salida del modelo y mostrarla en pantalla*

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_5.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_6.png)

Traduce este texto al idioma espa√±ol:

* La apariencia completa del diagrama es la siguiente, ejecuta el diagrama y ver√°s en la pantalla del juego el mensaje devuelto al imprimir el modelo grande.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_7.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_8.png)

###Utilizando el modelo de OpenAI en el plan de acci√≥n

* En el panel de control, haz clic derecho para crear un nodo `Enviar solicitud de chat OpenAI en el mundo`

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_1.png)

Cree el nodo Options y configure `Stream=true, Api Key="su clave de API de OpenAI"`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_2.png)

Cree Mensajes, a√±ada un Mensaje del Sistema y un Mensaje de Usuario respectivamente.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_4.png)

* Crear un delegado que acepte la informaci√≥n de salida del modelo y la imprima en la pantalla.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_5.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_6.png)

Traduce este texto al idioma espa√±ol:

* Una vez que ejecutes el blueprint completo, podr√°s ver en la pantalla del juego el mensaje que devuelve al imprimir el gran modelo.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_3.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_4.png)

##Registro de actualizaciones

### v1.3.3 - 2024.11.25

Apoyo a UE-5.5

* **Correcci√≥n de errores**: Se ha solucionado el problema de que ciertos dise√±os no funcionaban.

### v1.3.2 - 2024.10.10

#### Bugfix

Corregir el fallo de cllama al detener manualmente la solicitud.

Corregir el problema en la versi√≥n de descarga de la tienda en Windows donde no se puede encontrar el archivo ggml.dll o llama.dll al empaquetar.

* Al crear una solicitud, se verifica si se encuentra en el hilo del juego, CreateRequest se comprueba en el hilo del juego

### v1.3.1 - 2024.9.30

A√±adir un SystemTemplateViewer, para ver y utilizar cientos de plantillas de configuraci√≥n del sistema.

#### Bugfix

Reparar el plugin descargado desde la tienda, llama.cpp no puede encontrar la biblioteca de enlace.

* Soluci√≥n al problema de la longitud excesiva de la ruta de LLAMACpp

Corregir el error de enlace de llama.dll despu√©s de empaquetar Windows.

* Corregir el problema de lectura de la ruta del archivo en iOS/Android

Corregir el error al establecer el nombre de Cllame

### v1.3.0 - 2024.9.23

Actualizaci√≥n importante

Se ha integrado llama.cpp para admitir la ejecuci√≥n local sin conexi√≥n de modelos grandes.

### v1.2.0 - 2024.08.20

Apoyo a OpenAI Image Edit/Image Variation

Soporta la API de Ollama, capaz de obtener autom√°ticamente la lista de modelos admitidos por Ollama.

### v1.1.0 - 2024.08.07

Respaldar el plan

### v1.0.0 - 2024.08.05

* Funcionalidad b√°sica completa

Apoyo a OpenAI, Azure, Claude, Gemini

* Herramienta de chat con editor integrado y funciones completas.

--8<-- "footer_en.md"


> Este post est√° traducido usando ChatGPT, por favor [**feedback**](https://github.com/disenone/wiki_blog/issues/new) si hay alguna omisi√≥n.
