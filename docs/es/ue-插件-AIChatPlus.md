---
layout: post
title: 'Traduzca el texto a espa√±ol:


  Documentaci√≥n de la extensi√≥n UE AIChatPlus.'
tags:
- dev
- game
- UE
- UnreanEngine
- UE4
- UE5
- Editor
- Editor Plus
- Editor Plugin
- AI Chat
- Chatbot
- Image Generation
- OpenAI
- Azure
- Claude
- Gemini
- Ollama
description: 'Traduce este texto al espa√±ol:


  Documento de instrucciones del complemento UE AIChatPlus'
---

<meta property="og:title" content="UE Êèí‰ª∂ AIChatPlus ËØ¥ÊòéÊñáÊ°£" />

#Documento de instrucciones del complemento UE AIChatPlus

##Repositorio p√∫blico

[UE.AIChatPlus.Public](https://github.com/disenone/UE.AIChatPlus.Public)

##Obtener complemento

[AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

##Introducci√≥n del complemento

Esta extensi√≥n es compatible con UE5.2+.

UA.AIChatPlus es un complemento de UnrealEngine que permite la comunicaci√≥n con diversos servicios de chat de inteligencia artificial GPT. Actualmente, admite servicios como OpenAI (ChatGPT, DALL-E), Azure OpenAI (ChatGPT, DALL-E), Claude, Google Gemini, Ollama, y llama.cpp en modo offline local. En el futuro, se seguir√°n a√±adiendo m√°s proveedores de servicios. Su implementaci√≥n se basa en solicitudes REST as√≠ncronas, lo que garantiza un rendimiento eficiente y facilita la integraci√≥n de estos servicios de chat de IA para los desarrolladores de Unreal Engine.

Al mismo tiempo, UE.AIChatPlus tambi√©n incluye una herramienta de edici√≥n que permite utilizar directamente estos servicios de chat de IA en el editor para generar texto e im√°genes, analizar im√°genes, y m√°s.

##Instrucciones de uso

###Herramienta de chat del editor

La barra de men√∫ Herramientas -> AIChatPlus -> AIChat abre la herramienta de chat del editor proporcionada por el complemento.

![](assets/img/2024-ue-aichatplus/chat_tool3.png)


El soporte de la herramienta incluye generaci√≥n de texto, chat de texto, generaci√≥n de im√°genes y an√°lisis de im√°genes.

La interfaz de la herramienta es, en t√©rminos generales:

![text chat](assets/img/2024-ue-aichatplus/chat_tool2.png)

![image chat](assets/img/2024-ue-aichatplus/chat_tool.png)

####**Funci√≥n principal**

* Modelo grande sin conexi√≥n: Integraci√≥n de la biblioteca llama.cpp para admitir la ejecuci√≥n sin conexi√≥n de modelos grandes a nivel local

Crear un nuevo chat de texto: haz clic en el bot√≥n `New Chat` en la esquina inferior izquierda para iniciar una nueva conversaci√≥n de texto.

* Generaci√≥n de im√°genes: haz clic en el bot√≥n `New Image Chat` en la esquina inferior izquierda para iniciar una nueva sesi√≥n de generaci√≥n de im√°genes.

An√°lisis de im√°genes: Algunos servicios de chat de `New Chat` admiten el env√≠o de im√°genes, como Claude, Google Gemini. Simplemente haz clic en los botones üñºÔ∏è o üé® encima del cuadro de entrada para cargar la imagen que deseas enviar.

* Apoyo a Blueprint: Apoyo para la creaci√≥n de solicitudes de API de Blueprint, para funciones como chat de texto, generaci√≥n de im√°genes, entre otros.

Establecer el personaje de chat actual: El men√∫ desplegable en la parte superior del cuadro de chat se puede utilizar para seleccionar el personaje actual que enviar√° el texto, lo que permite simular diferentes roles para ajustar la conversaci√≥n de IA.

Borrar conversaci√≥n: El bot√≥n ‚ùå en la parte superior de la ventana de chat permite eliminar el historial de mensajes de la conversaci√≥n actual.

* Plantilla de di√°logo: incorpora cientos de plantillas de configuraci√≥n de di√°logo para facilitar el manejo de problemas comunes.

Establecimientos globales: al hacer clic en el bot√≥n `Setting` en la esquina inferior izquierda, se abre la ventana de establecimientos globales. Puede configurar el chat de texto predeterminado, el servicio de API para generar im√°genes y ajustar los par√°metros espec√≠ficos de cada servicio de API. Los establecimientos se guardar√°n autom√°ticamente en la ruta del proyecto `$(ProjectFolder)/Saved/AIChatPlusEditor`.

* Configuraci√≥n de conversaci√≥n: al hacer clic en el bot√≥n de configuraci√≥n en la parte superior del cuadro de chat, se puede abrir la ventana de configuraci√≥n de la conversaci√≥n actual. Permite modificar el nombre de la conversaci√≥n, el servicio de API utilizado en la conversaci√≥n, y establecer par√°metros espec√≠ficos de API para cada conversaci√≥n de manera independiente. La configuraci√≥n de la conversaci√≥n se guarda autom√°ticamente en `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions`

* Modificaci√≥n de contenido del chat: Al colocar el rat√≥n sobre el contenido del chat, aparecer√° un bot√≥n de configuraci√≥n del contenido individual del chat, que permite regenerar, modificar, copiar o eliminar el contenido, as√≠ como regenerar contenido debajo (para el contenido de usuario).

* Exploraci√≥n de im√°genes: Para la generaci√≥n de im√°genes, al hacer clic en una imagen se abrir√° la ventana de visualizaci√≥n de im√°genes (ImageViewer), que permite guardar la imagen como PNG/UE Texture. Las Texturas se pueden ver directamente en el Explorador de contenido (Content Browser), facilitando su uso dentro del editor. Tambi√©n se cuenta con funciones para eliminar im√°genes, regenerarlas, continuar generando m√°s im√°genes, entre otras. Para los editores en Windows, tambi√©n se puede copiar im√°genes, permitiendo copiarlas directamente al portapapeles para un uso conveniente. Las im√°genes generadas en la sesi√≥n se guardar√°n autom√°ticamente en la carpeta de cada sesi√≥n, generalmente en la ruta `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions/${GUID}/images`.

Plan:

![blueprint](assets/img/2024-ue-aichatplus/blueprint.png)

Configuraci√≥n global:

![global settings](assets/img/2024-ue-aichatplus/global_setting.png)

Configuraci√≥n de la conversaci√≥n:

![session settings](assets/img/2024-ue-aichatplus/session_setting.png)

Modificar el contenido del chat:

![chat edit](assets/img/2024-ue-aichatplus/chat_edit.png)

Visor de im√°genes:

![image viewer](assets/img/2024-ue-aichatplus/image_viewer.png)

Utilizaci√≥n de modelos grandes sin conexi√≥n

![offline model](assets/img/2024-ue-aichatplus/offline_model.png)

Plantilla de di√°logo

![system template](assets/img/2024-ue-aichatplus/system_template.png)

###Presentaci√≥n del c√≥digo principal

En la actualidad, el complemento se divide en los siguientes m√≥dulos:

* AIChatPlusCommon: El m√≥dulo de tiempo de ejecuci√≥n, responsable de manejar las solicitudes de env√≠o de diversas interfaces de API de IA y de analizar el contenido de las respuestas.

* AIChatPlusEditor: M√≥dulo de edici√≥n, encargado de implementar la herramienta de chat de IA del editor.

* AIChatPlusCllama: M√≥dulo de tiempo de ejecuci√≥n (Runtime), encargado de encapsular la interfaz y los par√°metros de llama.cpp, para llevar a cabo la ejecuci√≥n sin conexi√≥n de grandes modelos.

* Thirdparty/LLAMACpp: M√≥dulo de terceros en tiempo de ejecuci√≥n (Runtime) que integra la biblioteca din√°mica y archivos de cabecera de llama.cpp.

El UClass responsable de enviar las solicitudes es FAIChatPlus_xxxChatRequest, cada servicio API tiene su propio UClass de solicitud independiente. Las respuestas a las solicitudes se obtienen a trav√©s de UAIChatPlus_ChatHandlerBase / UAIChatPlus_ImageHandlerBase, solo es necesario registrar los delegados de devoluci√≥n de llamada correspondientes.

Antes de enviar la solicitud, es necesario configurar los par√°metros de la API y el mensaje a enviar, esto se hace a trav√©s de FAIChatPlus_xxxChatRequestBody. El contenido espec√≠fico de la respuesta tambi√©n se analiza en FAIChatPlus_xxxChatResponseBody, se puede obtener el ResponseBody a trav√©s de una interfaz espec√≠fica al recibir la devoluci√≥n de llamada.

M√°s detalles del c√≥digo fuente est√°n disponibles en la tienda de Unreal Engine: [AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

###Gu√≠a de uso

####Utilice el modelo fuera de l√≠nea del editor de herramientas llama.cpp

Traduce este texto al idioma espa√±ol:

El siguiente texto describe c√≥mo utilizar el modelo offline llamado llama.cpp en la herramienta del editor AIChatPlus.

* En primer lugar, descarga el modelo sin conexi√≥n desde el sitio web de HuggingFace: [Qwen1.5-1.8B-Chat-Q8_0.gguf](https://huggingface.co/second-state/Qwen1.5-1.8B-Chat-GGUF/resolve/main/Qwen1.5-1.8B-Chat-Q8_0.gguf)

Coloque el modelo en una carpeta espec√≠fica, por ejemplo, en el directorio Content/LLAMA del proyecto de juegos.

	```shell
	E:/UE/projects/FP_Test1/Content/LLAMA
	> ls
	qwen1.5-1_8b-chat-q8_0.gguf*
	```

Abre la herramienta de edici√≥n AIChatPlus: Herramientas -> AIChatPlus -> AIChat, crea una nueva sesi√≥n de chat y abre la p√°gina de ajustes de la sesi√≥n.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_1.png)

Establecer Api en Cllama, activar Configuraciones de Api Personalizadas, y agregar la ruta de b√∫squeda de modelos, luego seleccionar el modelo.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_2.png)

Comience la conversaci√≥n!!

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_3.png)

####El c√≥digo utiliza el modelo offline llama.cpp

Traduce este texto al idioma espa√±ol:

El siguiente documento describe c√≥mo utilizar el modelo sin conexi√≥n llama.cpp en el c√≥digo.

* Primero, tambi√©n necesitas descargar el archivo del modelo en Content/LLAMA.

Modificar el c√≥digo para agregar un comando y enviar un mensaje al modelo sin conexi√≥n dentro del comando.

	```c++
	#include "Common/AIChatPlus_Log.h"
	#include "Common_Cllama/AIChatPlus_CllamaChatRequest.h"

	void AddTestCommand()
	{
		IConsoleManager::Get().RegisterConsoleCommand(
			TEXT("AIChatPlus.TestChat"),
			TEXT("Test Chat."),
			FConsoleCommandDelegate::CreateLambda([]()
			{
				if (!FModuleManager::GetModulePtr<FAIChatPlusCommon>(TEXT("AIChatPlusCommon"))) return;

				TWeakObjectPtr<UAIChatPlus_ChatHandlerBase> HandlerObject = UAIChatPlus_ChatHandlerBase::New();
				// Cllama
				FAIChatPlus_CllamaChatRequestOptions Options;
				Options.ModelPath.FilePath = FPaths::ProjectContentDir() / "LLAMA" / "qwen1.5-1_8b-chat-q8_0.gguf";
				Options.NumPredict = 400;
				Options.bStream = true;
				// Options.StopSequences.Emplace(TEXT("json"));
				auto RequestPtr = UAIChatPlus_CllamaChatRequest::CreateWithOptionsAndMessages(
					Options,
					{
						{"You are a chat bot", EAIChatPlus_ChatRole::System},
						{"who are you", EAIChatPlus_ChatRole::User}
					});

				HandlerObject->BindChatRequest(RequestPtr);
				const FName ApiName = TEnumTraits<EAIChatPlus_ChatApiProvider>::ToName(RequestPtr->GetApiProvider());

				HandlerObject->OnMessage.AddLambda([ApiName](const FString& Message)
				{
					UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] Message: [%s]"), *ApiName.ToString(), *Message);
				});
				HandlerObject->OnStarted.AddLambda([ApiName]()
				{
					UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestStarted"), *ApiName.ToString());
				});
				HandlerObject->OnFailed.AddLambda([ApiName](const FAIChatPlus_ResponseErrorBase& InError)
				{
					UE_LOG(AIChatPlus_Internal, Error, TEXT("TestChat[%s] RequestFailed: %s "), *ApiName.ToString(), *InError.GetDescription());
				});
				HandlerObject->OnUpdated.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
				{
					UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestUpdated"), *ApiName.ToString());
				});
				HandlerObject->OnFinished.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
				{
					UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestFinished"), *ApiName.ToString());
				});

				RequestPtr->SendRequest();
			}),
			ECVF_Default
		);
	}
	```

* Despu√©s de volver a compilar, puedes ver los resultados de la salida del modelo grande en el registro de salida OutputLog al usar comandos en la ventana Cmd del editor.

![guide code](assets/img/2024-ue-aichatplus/guide_code_1.png)

####La impresi√≥n azul utiliza el modelo fuera de l√≠nea llama.cpp

todo

###Actualizaci√≥n del registro

#### v1.3.1 - 2024.9.30

Agrega un SystemTemplateViewer que permita ver y utilizar cientos de plantillas de configuraci√≥n de sistema.

##### Bugfix

Reparar el plugin descargado desde la tienda, llama.cpp no puede encontrar la biblioteca de enlaces.
‰øÆÂ§ç LLAMACpp Ë∑ØÂæÑËøáÈïøÈóÆÈ¢ò

Solucionar el problema de ruta demasiado larga de LLAMACpp
Reparar el error de enlace llama.dll despu√©s de empaquetar Windows
Corregir problema de lectura de ruta de archivos en iOS/Android.
* Corregido el error de configuraci√≥n de Cllame establecer nombre

#### v1.3.0 - 2024.9.23

Actualizaci√≥n importante

* Integrado llama.cpp, compatible con la ejecuci√≥n offline de grandes modelos localmente

#### v1.2.0 - 2024.08.20

Apoyo a OpenAI Image Edit / Image Variation

Apoya la API de Ollama, apoya la obtenci√≥n autom√°tica de la lista de modelos admitidos por Ollama

#### v1.1.0 - 2024.08.07

Apoyar el plan.

#### v1.0.0 - 2024.08.05

Funcionalidad b√°sica completa

Apoyo a OpenAI, Azure, Claude, Gemini.

* Herramienta de chat con editor integrado y funciones completas

--8<-- "footer_en.md"


> Este post est√° traducido usando ChatGPT, por favor [**feedback**](https://github.com/disenone/wiki_blog/issues/new) si hay alguna omisi√≥n.
