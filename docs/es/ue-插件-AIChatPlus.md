---
layout: post
title: Documento de instrucciones del complemento AIChatPlus de la UE.
tags:
- dev
- game
- UE
- UnreanEngine
- UE4
- UE5
- Editor
- Editor Plus
- Editor Plugin
- AI Chat
- Chatbot
- Image Generation
- OpenAI
- Azure
- Claude
- Gemini
- Ollama
description: Documentaci√≥n de UE Plug-in AIChatPlus
---

<meta property="og:title" content="UE Êèí‰ª∂ AIChatPlus ËØ¥ÊòéÊñáÊ°£" />

#Documento de instrucciones del complemento UE AIChatPlus

##Repositorio p√∫blico

[UE.AIChatPlus.Public](https://github.com/disenone/UE.AIChatPlus.Public)

##Obtener complemento

[AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

##Introducci√≥n del complemento

Este complemento es compatible con UE5.2+. 

UE.AIChatPlus es un complemento de UnrealEngine que implementa la comunicaci√≥n con varios servicios de chat de IA GPT. Actualmente, admite servicios como OpenAI (ChatGPT, DALL-E), Azure OpenAI (ChatGPT, DALL-E), Claude, Google Gemini, Ollama, llama.cpp para uso local sin conexi√≥n. En el futuro, seguir√° agregando soporte para m√°s proveedores de servicios. Su implementaci√≥n se basa en solicitudes REST as√≠ncronas, lo que garantiza un rendimiento eficiente y facilita a los desarrolladores de Unreal Engine conectarse a estos servicios de chat de IA.

Al mismo tiempo, UE.AIChatPlus tambi√©n incluye una herramienta de edici√≥n que le permite utilizar directamente estos servicios de chat de IA en el editor para crear texto e im√°genes, analizar im√°genes, etc.

##Instrucciones de Uso

###Herramienta de chat del editor

El men√∫ Tools -> AIChatPlus -> AIChat abre la herramienta de chat del editor proporcionada por el complemento.

![](assets/img/2024-ue-aichatplus/chat_tool3.png)


El software ofrece soporte para generaci√≥n de texto, chat de texto, generaci√≥n de im√°genes y an√°lisis de im√°genes.

La interfaz de la herramienta es aproximadamente:

![text chat](assets/img/2024-ue-aichatplus/chat_tool2.png)

![image chat](assets/img/2024-ue-aichatplus/chat_tool.png)

####Funci√≥n principal

* Modelo grande sin conexi√≥n: Integraci√≥n de la biblioteca llama.cpp, que permite la ejecuci√≥n sin conexi√≥n de modelos grandes a nivel local

* Chat de texto: haz clic en el bot√≥n `New Chat` en la esquina inferior izquierda para crear una nueva conversaci√≥n de chat de texto.

* Generaci√≥n de im√°genes: haz clic en el bot√≥n `New Image Chat` en la esquina inferior izquierda para iniciar una nueva sesi√≥n de generaci√≥n de im√°genes.

* An√°lisis de imagen: Algunos servicios de chat de `New Chat` admiten el env√≠o de im√°genes, como Claude, Google Gemini. Simplemente haz clic en el bot√≥n üñºÔ∏è o üé® sobre el cuadro de entrada para cargar la imagen que deseas enviar.

Apoyo para Blueprint: apoyo para crear solicitudes de API con Blueprint, realizando funciones como chat de texto, generaci√≥n de im√°genes, entre otras.

Establecer el rol actual de la conversaci√≥n: El men√∫ desplegable en la parte superior del cuadro de chat permite seleccionar el rol actual del texto enviado, lo que permite simular diferentes roles para ajustar la conversaci√≥n de la IA.

Borrar conversaci√≥n: Pulsar la ‚ùå en la parte superior de la ventana de chat borra el historial de mensajes de la conversaci√≥n actual.

* Plantilla de di√°logo: Incorpora cientos de plantillas de configuraci√≥n de di√°logo para facilitar el manejo de problemas comunes.

Translate these text into Spanish language:

* Configuraci√≥n global: hace clic en el bot√≥n `Setting` en la esquina inferior izquierda para abrir la ventana de configuraci√≥n global. Puedes definir el chat de texto predeterminado, el servicio de API para generar im√°genes y establecer los par√°metros espec√≠ficos para cada servicio de API. La configuraci√≥n se guardar√° autom√°ticamente en la ruta del proyecto `$(ProjectFolder)/Saved/AIChatPlusEditor`.

* Configuraci√≥n de la conversaci√≥n: Al hacer clic en el bot√≥n de configuraci√≥n en la parte superior de la ventana de chat, se puede abrir la ventana de configuraci√≥n de la conversaci√≥n actual. Se admite cambiar el nombre de la conversaci√≥n, modificar el servicio API utilizado en la conversaci√≥n y configurar de forma independiente los par√°metros espec√≠ficos de API utilizados en cada conversaci√≥n. La configuraci√≥n de la conversaci√≥n se guarda autom√°ticamente en `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions`

Modificar contenido del chat: Al pasar el mouse sobre el contenido del chat, aparecer√° un bot√≥n de configuraci√≥n para dicho contenido, que permitir√° regenerarlo, editarlo, copiarlo, eliminarlo o regenerar contenido debajo (para contenido generado por el usuario).

* Visor de im√°genes: para la generaci√≥n de im√°genes, al hacer clic en una imagen se abrir√° la ventana de visualizaci√≥n de im√°genes (ImageViewer), que permite guardar la imagen como PNG/Textura UE, las texturas pueden verse directamente en el explorador de contenido (Content Browser), facilitando su uso dentro del editor. Tambi√©n se puede eliminar, regenerar o seguir generando m√°s im√°genes. Para los editores en Windows, tambi√©n es posible copiar im√°genes, lo que permite copiarlas directamente al portapapeles para un uso m√°s conveniente. Las im√°genes generadas en la sesi√≥n se guardar√°n autom√°ticamente en la carpeta de cada sesi√≥n, generalmente en la ruta `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions/${GUID}/images`.

Plan:

![blueprint](assets/img/2024-ue-aichatplus/blueprint.png)

Configuraci√≥n Global:

![global settings](assets/img/2024-ue-aichatplus/global_setting.png)

Ajustes de la conversaci√≥n:

![session settings](assets/img/2024-ue-aichatplus/session_setting.png)

Modificar el contenido del chat:

![chat edit](assets/img/2024-ue-aichatplus/chat_edit.png)

Visor de im√°genes:

![image viewer](assets/img/2024-ue-aichatplus/image_viewer.png)

Utilizaci√≥n de modelos grandes sin conexi√≥n

![offline model](assets/img/2024-ue-aichatplus/offline_model.png)

Plantilla de di√°logo

![system template](assets/img/2024-ue-aichatplus/system_template.png)

###Introducci√≥n al c√≥digo central

En la actualidad, el complemento se divide en los siguientes m√≥dulos:

* AIChatPlusCommon: M√≥dulo de tiempo de ejecuci√≥n (Runtime), encargado de manejar diferentes solicitudes de API de inteligencia artificial y analizar el contenido de las respuestas.

* AIChatPlusEditor: M√≥dulo de editor, encargado de implementar la herramienta de chat de IA del editor.

* AIChatPlusCllama: M√≥dulo de tiempo de ejecuci√≥n (Runtime), encargado de encapsular la interfaz y los par√°metros de llama.cpp, para lograr la ejecuci√≥n offline de modelos grandes

* Thirdparty/LLAMACpp: M√≥dulo de terceros en tiempo de ejecuci√≥n (Runtime) que integra la biblioteca din√°mica y los archivos de cabecera de llama.cpp.

Traduzca este texto al idioma espa√±ol:

El UClass responsable espec√≠fico de enviar la solicitud es FAIChatPlus_xxxChatRequest; cada servicio API tiene su propio UClass de solicitud independiente. Las respuestas a las solicitudes se obtienen a trav√©s de dos UClass diferentes, UAIChatPlus_ChatHandlerBase y UAIChatPlus_ImageHandlerBase; solo es necesario registrar los delegados de devoluci√≥n de llamada correspondientes.

Antes de enviar la solicitud, es necesario configurar los par√°metros de la API y el mensaje a enviar, esto se hace a trav√©s de la FAIChatPlus_xxxChatRequestBody. La respuesta espec√≠fica tambi√©n se analiza en el FAIChatPlus_xxxChatResponseBody, y al recibir la devoluci√≥n de llamada, se puede obtener el ResponseBody a trav√©s de una interfaz espec√≠fica.

M√°s detalles del c√≥digo fuente disponibles en la tienda de Unreal Engine: [AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

##Gu√≠a de uso

###Utilice el modelo fuera de l√≠nea llama.cpp con la herramienta del editor.

Traduce este texto al idioma espa√±ol:

Instrucciones para usar el modelo sin conexi√≥n llama.cpp en la herramienta de edici√≥n AIChatPlus.

Descargue el modelo sin conexi√≥n desde el sitio web de HuggingFace: [Qwen1.5-1.8B-Chat-Q8_0.gguf](https://huggingface.co/second-state/Qwen1.5-1.8B-Chat-GGUF/resolve/main/Qwen1.5-1.8B-Chat-Q8_0.gguf)

Coloque el modelo en una carpeta espec√≠fica, por ejemplo en el directorio Content/LLAMA del proyecto de juego.

```shell
E:/UE/projects/FP_Test1/Content/LLAMA
> ls
qwen1.5-1_8b-chat-q8_0.gguf*
```

Abra la herramienta de edici√≥n AIChatPlus: Herramientas -> AIChatPlus -> AIChat, cree una nueva sesi√≥n de chat y abra la p√°gina de configuraci√≥n de la sesi√≥n.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_1.png)

Establece Api en Cllama, activa la Configuraci√≥n de Api Personalizada, a√±ade rutas de b√∫squeda de modelos y elige un modelo.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_2.png)

Comenzar a chatear!!

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_3.png)

###El c√≥digo utiliza el modelo fuera de l√≠nea llama.cpp.

Translate these text into Spanish language:

La siguiente explicaci√≥n muestra c√≥mo utilizar el modelo offline llama.cpp en el c√≥digo.

Primero, tambi√©n necesitas descargar el archivo del modelo en Content/LLAMA.

Modifica el c√≥digo para agregar un comando y enviar un mensaje al modelo sin conexi√≥n dentro del comando.

```c++
#include "Common/AIChatPlus_Log.h"
#include "Common_Cllama/AIChatPlus_CllamaChatRequest.h"

void AddTestCommand()
{
	IConsoleManager::Get().RegisterConsoleCommand(
		TEXT("AIChatPlus.TestChat"),
		TEXT("Test Chat."),
		FConsoleCommandDelegate::CreateLambda([]()
		{
			if (!FModuleManager::GetModulePtr<FAIChatPlusCommon>(TEXT("AIChatPlusCommon"))) return;

			TWeakObjectPtr<UAIChatPlus_ChatHandlerBase> HandlerObject = UAIChatPlus_ChatHandlerBase::New();
			// Cllama
			FAIChatPlus_CllamaChatRequestOptions Options;
			Options.ModelPath.FilePath = FPaths::ProjectContentDir() / "LLAMA" / "qwen1.5-1_8b-chat-q8_0.gguf";
			Options.NumPredict = 400;
			Options.bStream = true;
			// Options.StopSequences.Emplace(TEXT("json"));
			auto RequestPtr = UAIChatPlus_CllamaChatRequest::CreateWithOptionsAndMessages(
				Options,
				{
					{"You are a chat bot", EAIChatPlus_ChatRole::System},
					{"who are you", EAIChatPlus_ChatRole::User}
				});

			HandlerObject->BindChatRequest(RequestPtr);
			const FName ApiName = TEnumTraits<EAIChatPlus_ChatApiProvider>::ToName(RequestPtr->GetApiProvider());

			HandlerObject->OnMessage.AddLambda([ApiName](const FString& Message)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] Message: [%s]"), *ApiName.ToString(), *Message);
			});
			HandlerObject->OnStarted.AddLambda([ApiName]()
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestStarted"), *ApiName.ToString());
			});
			HandlerObject->OnFailed.AddLambda([ApiName](const FAIChatPlus_ResponseErrorBase& InError)
			{
				UE_LOG(AIChatPlus_Internal, Error, TEXT("TestChat[%s] RequestFailed: %s "), *ApiName.ToString(), *InError.GetDescription());
			});
			HandlerObject->OnUpdated.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestUpdated"), *ApiName.ToString());
			});
			HandlerObject->OnFinished.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestFinished"), *ApiName.ToString());
			});

			RequestPtr->SendRequest();
		}),
		ECVF_Default
	);
}
```

* Despu√©s de volver a compilar, simplemente utiliza el comando en el editor Cmd para ver los resultados de la salida del gran modelo en el registro OutputLog.

![guide code](assets/img/2024-ue-aichatplus/guide_code_1.png)

###Traduce este texto al espa√±ol:

Diagrama de uso del modelo fuera de l√≠nea llama.cpp

La siguiente explicaci√≥n detalla c√≥mo usar el modelo fuera de l√≠nea llama.cpp en un blueprint.

En el blueprint, crea un nodo haciendo clic derecho llamado `Enviar solicitud de chat de Cllama`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_1.png)

Crear nodo de Options y establecer `Stream=true, ModelPath="E:\UE\projects\FP_Test1\Content\LLAMA\qwen1.5-1_8b-chat-q8_0.gguf"`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_2.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_3.png)

* Cree mensajes, agregue un mensaje de sistema y un mensaje de usuario respectivamente

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_4.png)

*Establecer un Delegado que reciba la salida del modelo e imprima en la pantalla*

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_5.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_6.png)

Traduzca este texto al idioma espa√±ol:

* La apariencia de un dise√±o completo es as√≠; al ejecutarlo, se puede ver en la pantalla del juego el mensaje que devuelve la impresi√≥n del modelo grande.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_7.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_8.png)

##Registros de actualizaci√≥n

### v1.3.3 - 2024.11.25

Soporte para UE-5.5

### v1.3.2 - 2024.10.10

#### Bugfix

* Reparar el choque de cllama al detener manualmente la solicitud
Corregir el problema de no poder encontrar los archivos ggml.dll y llama.dll al empaquetar la versi√≥n de descarga de la tienda en Windows.
* Durante la creaci√≥n de la solicitud, verificar si se encuentra en el GameThread.

### v1.3.1 - 2024.9.30

A√±adir un SystemTemplateViewer que te permita ver y utilizar cientos de plantillas de configuraci√≥n del sistema.

#### Bugfix

Reparar el complemento descargado desde la tienda, llama.cpp no puede encontrar la biblioteca de enlaces.
Corregir problema de ruta demasiado larga en LLAMACpp
Reparar el error de enlace llama.dll despu√©s de empaquetar en Windows
* Resolver problema de lectura de ruta de archivos en ios/android
Corregir el error de configuraci√≥n del nombre de `Cllame`.

### v1.3.0 - 2024.9.23

Actualizaci√≥n importante

* Integraci√≥n de llama.cpp, compatible con la ejecuci√≥n local sin conexi√≥n de modelos grandes.

### v1.2.0 - 2024.08.20

Apoyar OpenAI Image Edit/Image Variation

Apoyo a la API de Ollama, apoyo para obtener autom√°ticamente la lista de modelos admitidos por Ollama.

### v1.1.0 - 2024.08.07

Apoyar el plan.

### v1.0.0 - 2024.08.05

Funci√≥n b√°sica completa

Apoyo a OpenAI, Azure, Claude, Gemini.

* Herramienta de chat con editor incorporado totalmente funcional

--8<-- "footer_en.md"


> Este post est√° traducido usando ChatGPT, por favor [**feedback**](https://github.com/disenone/wiki_blog/issues/new) si hay alguna omisi√≥n.
