---
layout: post
title: Documentaci√≥n sobre el complemento de UE AIChatPlus.
tags:
- dev
- game
- UE
- UnreanEngine
- UE4
- UE5
- Editor
- Editor Plus
- Editor Plugin
- AI Chat
- Chatbot
- Image Generation
- OpenAI
- Azure
- Claude
- Gemini
- Ollama
description: Documento de instrucciones de UE Plugin AIChatPlus
---

<meta property="og:title" content="UE Êèí‰ª∂ AIChatPlus ËØ¥ÊòéÊñáÊ°£" />

#Documento de instrucciones del complemento AIChatPlus de UE

##Almac√©n p√∫blico

[UE.AIChatPlus.Public](https://github.com/disenone/UE.AIChatPlus.Public)

##Obtener complemento

[AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

##Introducci√≥n del complemento

Este complemento es compatible con UE5.2+.

UE.AIChatPlus es un complemento para UnrealEngine que permite la comunicaci√≥n con diversos servicios de chat de IA GPT. Actualmente admite servicios como OpenAI (ChatGPT, DALL-E), Azure OpenAI (ChatGPT, DALL-E), Claude, Google Gemini, Ollama y llama.cpp local sin conexi√≥n. En el futuro, se seguir√°n agregando m√°s proveedores de servicios. Su implementaci√≥n se basa en solicitudes REST as√≠ncronas, lo que garantiza un rendimiento eficiente y facilita la integraci√≥n de estos servicios de chat de IA para desarrolladores de UE.

UE.AIChatPlus tambi√©n incluye una herramienta de edici√≥n que te permite usar directamente los servicios de chat de inteligencia artificial en el editor para generar texto e im√°genes, analizar im√°genes, entre otras funciones.

##Instrucciones de uso

###Herramienta de chat del editor

El men√∫ Tools -> AIChatPlus -> AIChat abre una herramienta de chat de editor proporcionada por el complemento.

![](assets/img/2024-ue-aichatplus/chat_tool3.png)


La herramienta es compatible con la generaci√≥n de texto, chat de texto, generaci√≥n de im√°genes y an√°lisis de im√°genes.

La interfaz de la herramienta es aproximadamente:

![text chat](assets/img/2024-ue-aichatplus/chat_tool2.png)

![image chat](assets/img/2024-ue-aichatplus/chat_tool.png)

####Funci√≥n principal

* Modelo grande fuera de l√≠nea: integra la biblioteca llama.cpp, compatible con la ejecuci√≥n local fuera de l√≠nea de modelos grandes

* Chat de texto: haz clic en el bot√≥n `New Chat` en la esquina inferior izquierda para crear una nueva sesi√≥n de chat de texto.

* Generaci√≥n de im√°genes: haz clic en el bot√≥n `New Image Chat` en la esquina inferior izquierda para iniciar una nueva sesi√≥n de generaci√≥n de im√°genes.

* An√°lisis de im√°genes: Algunos servicios de chat de `New Chat` admiten el env√≠o de im√°genes, como Claude, Google Gemini. Simplemente haz clic en el bot√≥n üñºÔ∏è o üé® encima del cuadro de texto para cargar la imagen que deseas enviar.

Apoyo a Blueprint: Apoyo a la creaci√≥n de Blueprint para realizar solicitudes de API, completar funciones como chat de texto, generaci√≥n de im√°genes, etc.

Establecer el rol actual en la conversaci√≥n: el men√∫ desplegable en la parte superior del cuadro de chat permite seleccionar el rol actual para enviar texto, lo que permite simular diferentes roles para ajustar la conversaci√≥n de la inteligencia artificial (IA).

Vaciar conversaci√≥n: El bot√≥n ‚ùå en la parte superior de la ventana de chat puede borrar el historial de mensajes de la conversaci√≥n actual.

* Plantilla de di√°logo: incluye cientos de plantillas de configuraci√≥n de di√°logo para facilitar el manejo de problemas comunes.

Traduce este texto al idioma espa√±ol:

* Configuraci√≥n global: Haz clic en el bot√≥n `Setting` en la esquina inferior izquierda para abrir la ventana de configuraci√≥n global. Puedes establecer el chat de texto predeterminado, el servicio de API para generar im√°genes y configurar los par√°metros espec√≠ficos de cada servicio de API. La configuraci√≥n se guardar√° autom√°ticamente en la ruta del proyecto `$(ProjectFolder)/Saved/AIChatPlusEditor`.

* Configuraci√≥n de la conversaci√≥n: Haz clic en el bot√≥n de configuraci√≥n en la parte superior del cuadro de chat para abrir la ventana de configuraci√≥n de la conversaci√≥n actual. Es posible cambiar el nombre de la conversaci√≥n, modificar los servicios de API utilizados en la conversaci√≥n y establecer par√°metros espec√≠ficos de API para cada conversaci√≥n de forma independiente. La configuraci√≥n de la conversaci√≥n se guarda autom√°ticamente en `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions`

Modificar contenido del chat: Al colocar el mouse sobre el contenido del chat, aparecer√° un bot√≥n de configuraci√≥n para ese contenido de chat en particular, que permitir√° regenerar, modificar, copiar o eliminar dicho contenido, as√≠ como regenerar contenido debajo (si es contenido de usuario).

* Exploraci√≥n de im√°genes: Para la generaci√≥n de im√°genes, al hacer clic en una imagen se abrir√° la ventana de visualizaci√≥n de im√°genes (ImageViewer), que admite guardar im√°genes como PNG/UE Texture. Las Texturas se pueden ver directamente en el explorador de contenido (Content Browser), facilitando su uso dentro del editor. Tambi√©n se ofrece soporte para eliminar im√°genes, regenerarlas, continuar generando m√°s im√°genes, entre otras funciones. En el editor de Windows, tambi√©n se puede copiar im√°genes, lo que permite copiarlas directamente al portapapeles para facilitar su uso. Las im√°genes generadas en la sesi√≥n se guardar√°n autom√°ticamente en la carpeta de cada sesi√≥n, con la ruta habitualmente en `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions/${GUID}/images`.

Plan:

![blueprint](assets/img/2024-ue-aichatplus/blueprint.png)

Configuraci√≥n global:

![global settings](assets/img/2024-ue-aichatplus/global_setting.png)

Configuraci√≥n de la conversaci√≥n:

![session settings](assets/img/2024-ue-aichatplus/session_setting.png)

Modificar el contenido del chat:

![chat edit](assets/img/2024-ue-aichatplus/chat_edit.png)

Visor de im√°genes:

![image viewer](assets/img/2024-ue-aichatplus/image_viewer.png)

Utilizar grandes modelos sin conexi√≥n

![offline model](assets/img/2024-ue-aichatplus/offline_model.png)

Plantilla de di√°logo

![system template](assets/img/2024-ue-aichatplus/system_template.png)

###Introducci√≥n al c√≥digo principal

En la actualidad, el complemento se divide en los siguientes m√≥dulos:

* AIChatPlusCommon: M√≥dulo de tiempo de ejecuci√≥n (Runtime), encargado de manejar las solicitudes de env√≠o de varias interfaces de API de IA y analizar el contenido de las respuestas.

* AIChatPlusEditor: M√≥dulo de editor, responsable de implementar la herramienta de chat de inteligencia artificial en el editor.

* AIChatPlusCllama: M√≥dulo en tiempo de ejecuci√≥n (Runtime), encargado de encapsular la interfaz y los par√°metros de llama.cpp, para lograr la ejecuci√≥n offline de grandes modelos

* Thirdparty/LLAMACpp: M√≥dulo de terceros en tiempo de ejecuci√≥n (Runtime) que integra la biblioteca din√°mica y archivos de encabezado de llama.cpp.

El UClass responsable de enviar las solicitudes concretas es FAIChatPlus_xxxChatRequest. Cada servicio de API tiene su propio UClass de solicitud independiente. Las respuestas a las solicitudes se obtienen a trav√©s de dos UClass diferentes: UAIChatPlus_ChatHandlerBase y UAIChatPlus_ImageHandlerBase. Solo es necesario registrar los delegados de devoluci√≥n de llamada correspondientes.

Antes de enviar una solicitud, es necesario configurar los par√°metros de la API y el mensaje a enviar. Esto se hace a trav√©s de FAIChatPlus_xxxChatRequestBody. La respuesta espec√≠fica tambi√©n se analiza en FAIChatPlus_xxxChatResponseBody, y al recibir una respuesta, se puede obtener el ResponseBody a trav√©s de una interfaz espec√≠fica.

Se pueden encontrar m√°s detalles sobre el c√≥digo fuente en la tienda de UE: [AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

##Gu√≠a de uso

###Utilice el modelo fuera de l√≠nea del editor de herramientas llama.cpp.

Traduce este texto al idioma espa√±ol:

Las siguientes instrucciones detallan c√≥mo utilizar el modelo fuera de l√≠nea llama.cpp en la herramienta de edici√≥n AIChatPlus.

(https://huggingface.co/second-state/Qwen1.5-1.8B-Chat-GGUF/resolve/main/Qwen1.5-1.8B-Chat-Q8_0.gguf)

Coloca el modelo en una carpeta espec√≠fica, como por ejemplo en el directorio Content/LLAMA del proyecto del juego.

```shell
E:/UE/projects/FP_Test1/Content/LLAMA
> ls
qwen1.5-1_8b-chat-q8_0.gguf*
```

Abre la herramienta de edici√≥n AIChatPlus: Herramientas -> AIChatPlus -> AIChat, crea una sesi√≥n de chat y abre la p√°gina de configuraci√≥n de la sesi√≥n.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_1.png)

Establecer Api como Cllama, activar Configuraciones de Api Personalizadas, a√±adir ruta de b√∫squeda de modelos y seleccionar un modelo.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_2.png)

¬°Comenzar a chatear!¬°¬°

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_3.png)

###El c√≥digo utiliza el modelo fuera de l√≠nea llama.cpp

Traduce este texto al idioma Espa√±ol:

El siguiente texto explica c√≥mo utilizar el modelo fuera de l√≠nea llama.cpp en el c√≥digo.

Primero, tambi√©n necesitas descargar el archivo del modelo en Content/LLAMA.

Modifique el c√≥digo para agregar un comando y enviar un mensaje al modelo sin conexi√≥n dentro del comando.

```c++
#include "Common/AIChatPlus_Log.h"
#include "Common_Cllama/AIChatPlus_CllamaChatRequest.h"

void AddTestCommand()
{
	IConsoleManager::Get().RegisterConsoleCommand(
		TEXT("AIChatPlus.TestChat"),
		TEXT("Test Chat."),
		FConsoleCommandDelegate::CreateLambda([]()
		{
			if (!FModuleManager::GetModulePtr<FAIChatPlusCommon>(TEXT("AIChatPlusCommon"))) return;

			TWeakObjectPtr<UAIChatPlus_ChatHandlerBase> HandlerObject = UAIChatPlus_ChatHandlerBase::New();
			// Cllama
			FAIChatPlus_CllamaChatRequestOptions Options;
			Options.ModelPath.FilePath = FPaths::ProjectContentDir() / "LLAMA" / "qwen1.5-1_8b-chat-q8_0.gguf";
			Options.NumPredict = 400;
			Options.bStream = true;
			// Options.StopSequences.Emplace(TEXT("json"));
			auto RequestPtr = UAIChatPlus_CllamaChatRequest::CreateWithOptionsAndMessages(
				Options,
				{
					{"You are a chat bot", EAIChatPlus_ChatRole::System},
					{"who are you", EAIChatPlus_ChatRole::User}
				});

			HandlerObject->BindChatRequest(RequestPtr);
			const FName ApiName = TEnumTraits<EAIChatPlus_ChatApiProvider>::ToName(RequestPtr->GetApiProvider());

			HandlerObject->OnMessage.AddLambda([ApiName](const FString& Message)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] Message: [%s]"), *ApiName.ToString(), *Message);
			});
			HandlerObject->OnStarted.AddLambda([ApiName]()
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestStarted"), *ApiName.ToString());
			});
			HandlerObject->OnFailed.AddLambda([ApiName](const FAIChatPlus_ResponseErrorBase& InError)
			{
				UE_LOG(AIChatPlus_Internal, Error, TEXT("TestChat[%s] RequestFailed: %s "), *ApiName.ToString(), *InError.GetDescription());
			});
			HandlerObject->OnUpdated.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestUpdated"), *ApiName.ToString());
			});
			HandlerObject->OnFinished.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestFinished"), *ApiName.ToString());
			});

			RequestPtr->SendRequest();
		}),
		ECVF_Default
	);
}
```

Despu√©s de volver a compilar, puedes usar comandos en la consola del editor para ver los resultados de la salida del modelo grande en el registro OutputLog.

![guide code](assets/img/2024-ue-aichatplus/guide_code_1.png)

###Translate these text into Spanish language:

 El archivo de plano de planta utiliza el modelo fuera de l√≠nea llama.cpp

A continuaci√≥n se explica c√≥mo usar el modelo sin conexi√≥n llama.cpp en un blueprint.

Crea un nodo `Enviar solicitud de chat a Cllama` con clic derecho en el blueprint.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_1.png)

Crear un nodo de Opciones y establecer `Stream=true, ModelPath="E:\UE\projects\FP_Test1\Content\LLAMA\qwen1.5-1_8b-chat-q8_0.gguf"`

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_2.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_3.png)

* Crear mensajes, agregar un mensaje del sistema y un mensaje del usuario respectivamente

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_4.png)

*Crear un delegado que reciba la informaci√≥n de salida del modelo y la imprima en la pantalla*

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_5.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_6.png)

Translate these text into Spanish language:

* La representaci√≥n completa del blueprint se ve as√≠, ejecuta el blueprint y ver√° el mensaje devuelto en la pantalla del juego al imprimir el modelo grande.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_7.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_8.png)

##Registro de actualizaciones

### v1.3.2 - 2024.10.10

#### Bugfix

Reparar cllama que se bloquea al detener manualmente la solicitud.
Corregir el problema de falta de archivos ggml.dll y llama.dll al empaquetar la versi√≥n de descarga de Win en la tienda.
* Al crear una solicitud, se verifica si se encuentra en el hilo del juego, se comprueba en el hilo del juego.

### v1.3.1 - 2024.9.30

Agregue un SystemTemplateViewer, que le permitir√° ver y utilizar cientos de plantillas de configuraci√≥n del sistema.

#### Bugfix

Reparar el plugin descargado de la tienda, llama.cpp no puede encontrar la biblioteca de enlaces.
* Corregir el problema de la ruta demasiado larga en LLAMACpp
Corregir el error de enlace de llama.dll despu√©s de empaquetar en Windows.
Corrija el problema de lectura de la ruta de archivos en ios/android.
Corregir el error al establecer el nombre de Cllame

### v1.3.0 - 2024.9.23

Actualizaci√≥n importante

* Se ha integrado llama.cpp, para admitir la ejecuci√≥n sin conexi√≥n local de modelos grandes

### v1.2.0 - 2024.08.20

Apoyando la Edici√≥n de Im√°genes de OpenAI/Variedad de Im√°genes.

Apoya la API de Ollama, que permite obtener autom√°ticamente la lista de modelos admitidos por Ollama.

### v1.1.0 - 2024.08.07

Apoyar el plan (blueprint)

### v1.0.0 - 2024.08.05

*Funcionalidad b√°sica completa*

Apoyo a OpenAI, Azure, Claude, Gemini

* Herramienta de chat con editor integrado y funciones completas

--8<-- "footer_en.md"


> Este post est√° traducido usando ChatGPT, por favor [**feedback**](https://github.com/disenone/wiki_blog/issues/new) si hay alguna omisi√≥n.
